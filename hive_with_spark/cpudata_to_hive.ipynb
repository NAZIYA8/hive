{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "'''\n",
    "@Author: Naziya\n",
    "\n",
    "@Date: 2021-09-16\n",
    "\n",
    "@Last Modified by: Naziya\n",
    "\n",
    "@Last Modified : 2021-09-16\n",
    "\n",
    "@Title : Program Aim is to create a dataframe using spark and add it into the hive table.\n",
    "\n",
    "'''"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Creating spark sesion with hive support enable"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from LoggerFormat import logger\n",
    "try:\n",
    "    appName = \"PySpark MySQL Example - via mysql.connector\"\n",
    "    master = \"local\"\n",
    "    spark = SparkSession.builder.master(master).appName(appName).enableHiveSupport().getOrCreate()\n",
    "except Exception as e:\n",
    "    logger.error(e)\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "21/09/16 18:48:20 WARN Utils: Your hostname, naziya-Inspiron-N5110 resolves to a loopback address: 127.0.1.1; using 192.168.1.109 instead (on interface wlp9s0)\n",
      "21/09/16 18:48:20 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "21/09/16 18:48:21 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "Creating dataframe of csv file using spark and selecting only certain columns\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "try:\n",
    "    df = spark.read.csv(\"hdfs://localhost:9000/spark_sql/merged_CpuLogData.csv\",header=True)\n",
    "    df2 = df.select(\"user_name\",\"DateTime\",\"keyboard\",\"mouse\")\n",
    "    df2.createOrReplaceTempView('myview')\n",
    "except Exception as e:\n",
    "    logger.error(e)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "21/09/16 18:50:36 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "df2.show()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+--------------------+-------------------+--------+------+\n",
      "|           user_name|           DateTime|keyboard| mouse|\n",
      "+--------------------+-------------------+--------+------+\n",
      "|rahilstar11@gmail...|2019-09-16 12:55:03|     0.0|   0.0|\n",
      "|salinabodale73@gm...|2019-09-16 12:55:02|  2919.5| 888.0|\n",
      "|bhagyashrichalke2...|2019-09-16 12:55:01|   144.0|2886.0|\n",
      "|bhagyashrichalke2...|2019-09-16 13:00:01|    21.0|  44.0|\n",
      "|  iamnzm@outlook.com|2019-09-16 13:00:01|    41.0|8251.0|\n",
      "|deepshukla292@gma...|2019-09-16 13:00:01|   249.5|4266.0|\n",
      "|salinabodale73@gm...|2019-09-16 13:00:02|   135.5| 692.0|\n",
      "|sharlawar77@gmail...|2019-09-16 13:00:04|   303.0| 243.0|\n",
      "|rahilstar11@gmail...|2019-09-16 13:00:03|    22.5| 170.0|\n",
      "|salinabodale73@gm...|2019-09-16 13:05:01|   179.5| 108.0|\n",
      "|bhagyashrichalke2...|2019-09-16 13:05:02|   387.0| 676.0|\n",
      "|deepshukla292@gma...|2019-09-16 13:05:01|   165.0|5701.0|\n",
      "|  iamnzm@outlook.com|2019-09-16 13:05:02|    52.0|7971.0|\n",
      "|sharlawar77@gmail...|2019-09-16 13:05:04|    17.0|  72.0|\n",
      "|rahilstar11@gmail...|2019-09-16 13:05:04|    38.0|  68.0|\n",
      "|salinabodale73@gm...|2019-09-16 13:10:02|   310.5|  40.0|\n",
      "|bhagyashrichalke2...|2019-09-16 13:10:01|   360.0| 184.0|\n",
      "|deepshukla292@gma...|2019-09-16 13:10:01|     0.0|5392.0|\n",
      "|  iamnzm@outlook.com|2019-09-16 13:10:01|   100.0|5537.0|\n",
      "|sharlawar77@gmail...|2019-09-16 13:10:05|    28.0|   0.0|\n",
      "+--------------------+-------------------+--------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "df10 = spark.sql(\"show databases\")\n",
    "df10.show()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+---------+\n",
      "|namespace|\n",
      "+---------+\n",
      "|  default|\n",
      "|     test|\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "Now Adding dataframe into hive table using different methods"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "Method 1"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "try:\n",
    "    # Save df to a new table in Hive we just need database table name we can give anything\n",
    "    df2.write.mode(\"overwrite\").saveAsTable(\"test.test_data\")\n",
    "\n",
    "except Exception as e:\n",
    "    logger.error(e)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "21/09/16 18:50:59 WARN SessionState: METASTORE_FILTER_HOOK will be ignored, since hive.security.authorization.manager is set to instance of HiveAuthorizerFactory.\n",
      "21/09/16 18:51:00 WARN HiveConf: HiveConf of name hive.metastore.wm.default.pool.size does not exist\n",
      "21/09/16 18:51:00 WARN HiveConf: HiveConf of name hive.llap.task.scheduler.preempt.independent does not exist\n",
      "21/09/16 18:51:00 WARN HiveConf: HiveConf of name hive.llap.output.format.arrow does not exist\n",
      "21/09/16 18:51:00 WARN HiveConf: HiveConf of name hive.tez.llap.min.reducer.per.executor does not exist\n",
      "21/09/16 18:51:00 WARN HiveConf: HiveConf of name hive.arrow.root.allocator.limit does not exist\n",
      "21/09/16 18:51:00 WARN HiveConf: HiveConf of name hive.vectorized.use.checked.expressions does not exist\n",
      "21/09/16 18:51:00 WARN HiveConf: HiveConf of name hive.tez.dynamic.semijoin.reduction.for.mapjoin does not exist\n",
      "21/09/16 18:51:00 WARN HiveConf: HiveConf of name hive.vectorized.complex.types.enabled does not exist\n",
      "21/09/16 18:51:00 WARN HiveConf: HiveConf of name hive.server2.wm.worker.threads does not exist\n",
      "21/09/16 18:51:00 WARN HiveConf: HiveConf of name hive.repl.partitions.dump.parallelism does not exist\n",
      "21/09/16 18:51:00 WARN HiveConf: HiveConf of name hive.metastore.uri.selection does not exist\n",
      "21/09/16 18:51:00 WARN HiveConf: HiveConf of name hive.strict.checks.no.partition.filter does not exist\n",
      "21/09/16 18:51:00 WARN HiveConf: HiveConf of name hive.tez.dynamic.semijoin.reduction.for.dpp.factor does not exist\n",
      "21/09/16 18:51:00 WARN HiveConf: HiveConf of name hive.stats.filter.in.min.ratio does not exist\n",
      "21/09/16 18:51:00 WARN HiveConf: HiveConf of name hive.metastore.client.cache.initial.capacity does not exist\n",
      "21/09/16 18:51:00 WARN HiveConf: HiveConf of name hive.stats.ndv.estimate.percent does not exist\n",
      "21/09/16 18:51:00 WARN HiveConf: HiveConf of name hive.server2.webui.cors.allowed.methods does not exist\n",
      "21/09/16 18:51:00 WARN HiveConf: HiveConf of name hive.optimize.joinreducededuplication does not exist\n",
      "21/09/16 18:51:00 WARN HiveConf: HiveConf of name hive.metastore.client.cache.enabled does not exist\n",
      "21/09/16 18:51:00 WARN HiveConf: HiveConf of name hive.stats.fetch.bitvector does not exist\n",
      "21/09/16 18:51:00 WARN HiveConf: HiveConf of name hive.disable.unsafe.external.table.operations does not exist\n",
      "21/09/16 18:51:00 WARN HiveConf: HiveConf of name hive.materializedview.rewriting.incremental does not exist\n",
      "21/09/16 18:51:00 WARN HiveConf: HiveConf of name hive.server2.materializedviews.registry.impl does not exist\n",
      "21/09/16 18:51:00 WARN HiveConf: HiveConf of name hive.metastore.event.db.notification.api.auth does not exist\n",
      "21/09/16 18:51:00 WARN HiveConf: HiveConf of name hive.exec.orc.delta.streaming.optimizations.enabled does not exist\n",
      "21/09/16 18:51:00 WARN HiveConf: HiveConf of name hive.stats.ndv.algo does not exist\n",
      "21/09/16 18:51:00 WARN HiveConf: HiveConf of name hive.spark.job.max.tasks does not exist\n",
      "21/09/16 18:51:00 WARN HiveConf: HiveConf of name hive.msck.repair.batch.max.retries does not exist\n",
      "21/09/16 18:51:00 WARN HiveConf: HiveConf of name hive.prewarm.spark.timeout does not exist\n",
      "21/09/16 18:51:00 WARN HiveConf: HiveConf of name hive.optimize.update.table.properties.from.serde.list does not exist\n",
      "21/09/16 18:51:00 WARN HiveConf: HiveConf of name hive.llap.plugin.client.num.threads does not exist\n",
      "21/09/16 18:51:00 WARN HiveConf: HiveConf of name hive.test.bucketcodec.version does not exist\n",
      "21/09/16 18:51:00 WARN HiveConf: HiveConf of name hive.query.reexecution.enabled does not exist\n",
      "21/09/16 18:51:00 WARN HiveConf: HiveConf of name hive.materializedview.rewriting.time.window does not exist\n",
      "21/09/16 18:51:00 WARN HiveConf: HiveConf of name hive.query.reexecution.stats.cache.batch.size does not exist\n",
      "21/09/16 18:51:00 WARN HiveConf: HiveConf of name hive.server2.webui.cors.allowed.headers does not exist\n",
      "21/09/16 18:51:00 WARN HiveConf: HiveConf of name hive.join.inner.residual does not exist\n",
      "21/09/16 18:51:00 WARN HiveConf: HiveConf of name hive.server2.active.passive.ha.enable does not exist\n",
      "21/09/16 18:51:00 WARN HiveConf: HiveConf of name hive.llap.io.trace.always.dump does not exist\n",
      "21/09/16 18:51:00 WARN HiveConf: HiveConf of name hive.query.reexecution.stats.persist.scope does not exist\n",
      "21/09/16 18:51:00 WARN HiveConf: HiveConf of name hive.mm.allow.originals does not exist\n",
      "21/09/16 18:51:00 WARN HiveConf: HiveConf of name hive.internal.ss.authz.settings.applied.marker does not exist\n",
      "21/09/16 18:51:00 WARN HiveConf: HiveConf of name hive.compactor.compact.insert.only does not exist\n",
      "21/09/16 18:51:00 WARN HiveConf: HiveConf of name hive.txn.xlock.iow does not exist\n",
      "21/09/16 18:51:00 WARN HiveConf: HiveConf of name hive.spark.rsc.conf.list does not exist\n",
      "21/09/16 18:51:00 WARN HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist\n",
      "21/09/16 18:51:00 WARN HiveConf: HiveConf of name hive.llap.cache.defaultfs.only.native.fileid does not exist\n",
      "21/09/16 18:51:00 WARN HiveConf: HiveConf of name hive.spark.optimize.shuffle.serde does not exist\n",
      "21/09/16 18:51:00 WARN HiveConf: HiveConf of name hive.testing.remove.logs does not exist\n",
      "21/09/16 18:51:00 WARN HiveConf: HiveConf of name hive.distcp.privileged.doAs does not exist\n",
      "21/09/16 18:51:00 WARN HiveConf: HiveConf of name hive.strict.checks.orderby.no.limit does not exist\n",
      "21/09/16 18:51:00 WARN HiveConf: HiveConf of name hive.metastore.client.cache.expiry.time does not exist\n",
      "21/09/16 18:51:00 WARN HiveConf: HiveConf of name hive.llap.io.allocator.defrag.headroom does not exist\n",
      "21/09/16 18:51:00 WARN HiveConf: HiveConf of name hive.notification.event.consumers does not exist\n",
      "21/09/16 18:51:00 WARN HiveConf: HiveConf of name hive.vectorized.input.format.supports.enabled does not exist\n",
      "21/09/16 18:51:00 WARN HiveConf: HiveConf of name hive.metastore.client.cache.max.capacity does not exist\n",
      "21/09/16 18:51:00 WARN HiveConf: HiveConf of name hive.repl.dumpdir.clean.freq does not exist\n",
      "21/09/16 18:51:00 WARN HiveConf: HiveConf of name hive.spark.use.ts.stats.for.mapjoin does not exist\n",
      "21/09/16 18:51:00 WARN HiveConf: HiveConf of name hive.repl.dump.include.acid.tables does not exist\n",
      "21/09/16 18:51:00 WARN HiveConf: HiveConf of name hive.server2.webui.use.pam does not exist\n",
      "21/09/16 18:51:00 WARN HiveConf: HiveConf of name hive.query.reexecution.max.count does not exist\n",
      "21/09/16 18:51:00 WARN HiveConf: HiveConf of name hive.llap.io.share.object.pools does not exist\n",
      "21/09/16 18:51:00 WARN HiveConf: HiveConf of name hive.optimize.update.table.properties.from.serde does not exist\n",
      "21/09/16 18:51:00 WARN HiveConf: HiveConf of name hive.service.metrics.codahale.reporter.classes does not exist\n",
      "21/09/16 18:51:00 WARN HiveConf: HiveConf of name hive.tez.session.events.print.summary does not exist\n",
      "21/09/16 18:51:00 WARN HiveConf: HiveConf of name hive.llap.io.vrb.queue.limit.base does not exist\n",
      "21/09/16 18:51:00 WARN HiveConf: HiveConf of name hive.mm.avoid.s3.globstatus does not exist\n",
      "21/09/16 18:51:00 WARN HiveConf: HiveConf of name hive.server2.thrift.bind.port does not exist\n",
      "21/09/16 18:51:00 WARN HiveConf: HiveConf of name hive.repl.replica.functions.root.dir does not exist\n",
      "21/09/16 18:51:00 WARN HiveConf: HiveConf of name hive.query.results.cache.max.entry.lifetime does not exist\n",
      "21/09/16 18:51:00 WARN HiveConf: HiveConf of name hive.server2.limit.connections.per.user does not exist\n",
      "21/09/16 18:51:00 WARN HiveConf: HiveConf of name hive.server2.thrift.http.compression.enabled does not exist\n",
      "21/09/16 18:51:00 WARN HiveConf: HiveConf of name hive.vectorized.execution.ptf.enabled does not exist\n",
      "21/09/16 18:51:00 WARN HiveConf: HiveConf of name hive.optimize.shared.work.extended does not exist\n",
      "21/09/16 18:51:00 WARN HiveConf: HiveConf of name hive.vectorized.row.identifier.enabled does not exist\n",
      "21/09/16 18:51:00 WARN HiveConf: HiveConf of name hive.query.reexecution.always.collect.operator.stats does not exist\n",
      "21/09/16 18:51:00 WARN HiveConf: HiveConf of name hive.repl.dumpdir.ttl does not exist\n",
      "21/09/16 18:51:00 WARN HiveConf: HiveConf of name hive.local.time.zone does not exist\n",
      "21/09/16 18:51:00 WARN HiveConf: HiveConf of name hive.server2.tez.wm.am.registry.timeout does not exist\n",
      "21/09/16 18:51:00 WARN HiveConf: HiveConf of name hive.server2.active.passive.ha.registry.namespace does not exist\n",
      "21/09/16 18:51:00 WARN HiveConf: HiveConf of name hive.create.as.insert.only does not exist\n",
      "21/09/16 18:51:00 WARN HiveConf: HiveConf of name hive.llap.mapjoin.memory.oversubscribe.factor does not exist\n",
      "21/09/16 18:51:00 WARN HiveConf: HiveConf of name hive.arrow.batch.size does not exist\n",
      "21/09/16 18:51:00 WARN HiveConf: HiveConf of name hive.notification.sequence.lock.retry.sleep.interval does not exist\n",
      "21/09/16 18:51:00 WARN HiveConf: HiveConf of name hive.repl.approx.max.load.tasks does not exist\n",
      "21/09/16 18:51:00 WARN HiveConf: HiveConf of name hive.query.results.cache.enabled does not exist\n",
      "21/09/16 18:51:00 WARN HiveConf: HiveConf of name hive.legacy.schema.for.all.serdes does not exist\n",
      "21/09/16 18:51:00 WARN HiveConf: HiveConf of name hive.tez.dag.status.check.interval does not exist\n",
      "21/09/16 18:51:00 WARN HiveConf: HiveConf of name hive.druid.bitmap.type does not exist\n",
      "21/09/16 18:51:00 WARN HiveConf: HiveConf of name hive.spark.dynamic.partition.pruning.map.join.only does not exist\n",
      "21/09/16 18:51:00 WARN HiveConf: HiveConf of name hive.llap.memory.oversubscription.max.executors.per.query does not exist\n",
      "21/09/16 18:51:00 WARN HiveConf: HiveConf of name hive.llap.io.trace.size does not exist\n",
      "21/09/16 18:51:00 WARN HiveConf: HiveConf of name hive.llap.plugin.rpc.num.handlers does not exist\n",
      "21/09/16 18:51:00 WARN HiveConf: HiveConf of name hive.server2.wm.allow.any.pool.via.jdbc does not exist\n",
      "21/09/16 18:51:00 WARN HiveConf: HiveConf of name hive.vectorized.groupby.complex.types.enabled does not exist\n",
      "21/09/16 18:51:00 WARN HiveConf: HiveConf of name hive.avro.timestamp.skip.conversion does not exist\n",
      "21/09/16 18:51:00 WARN HiveConf: HiveConf of name hive.query.results.cache.nontransactional.tables.enabled does not exist\n",
      "21/09/16 18:51:00 WARN HiveConf: HiveConf of name hive.stats.correlated.multi.key.joins does not exist\n",
      "21/09/16 18:51:00 WARN HiveConf: HiveConf of name hive.metastore.db.type does not exist\n",
      "21/09/16 18:51:00 WARN HiveConf: HiveConf of name hive.streaming.auto.flush.check.interval.size does not exist\n",
      "21/09/16 18:51:00 WARN HiveConf: HiveConf of name hive.zookeeper.connection.timeout does not exist\n",
      "21/09/16 18:51:00 WARN HiveConf: HiveConf of name hive.query.reexecution.strategies does not exist\n",
      "21/09/16 18:51:00 WARN HiveConf: HiveConf of name hive.server2.limit.connections.per.user.ipaddress does not exist\n",
      "21/09/16 18:51:00 WARN HiveConf: HiveConf of name hive.llap.mapjoin.memory.monitor.check.interval does not exist\n",
      "21/09/16 18:51:00 WARN HiveConf: HiveConf of name hive.optimize.shared.work does not exist\n",
      "21/09/16 18:51:00 WARN HiveConf: HiveConf of name hive.stats.estimate does not exist\n",
      "21/09/16 18:51:00 WARN HiveConf: HiveConf of name hive.llap.io.allocator.discard.method does not exist\n",
      "21/09/16 18:51:00 WARN HiveConf: HiveConf of name hive.tez.cartesian-product.enabled does not exist\n",
      "21/09/16 18:51:00 WARN HiveConf: HiveConf of name hive.notification.sequence.lock.max.retries does not exist\n",
      "21/09/16 18:51:00 WARN HiveConf: HiveConf of name hive.heap.memory.monitor.usage.threshold does not exist\n",
      "21/09/16 18:51:00 WARN HiveConf: HiveConf of name hive.privilege.synchronizer.interval does not exist\n",
      "21/09/16 18:51:00 WARN HiveConf: HiveConf of name hive.vectorized.adaptor.suppress.evaluate.exceptions does not exist\n",
      "21/09/16 18:51:00 WARN HiveConf: HiveConf of name hive.materializedview.rebuild.incremental does not exist\n",
      "21/09/16 18:51:00 WARN HiveConf: HiveConf of name hive.query.results.cache.max.entry.size does not exist\n",
      "21/09/16 18:51:00 WARN HiveConf: HiveConf of name hive.spark.stage.max.tasks does not exist\n",
      "21/09/16 18:51:00 WARN HiveConf: HiveConf of name hive.testing.short.logs does not exist\n",
      "21/09/16 18:51:00 WARN HiveConf: HiveConf of name hive.streaming.auto.flush.enabled does not exist\n",
      "21/09/16 18:51:00 WARN HiveConf: HiveConf of name hive.spark.explain.user does not exist\n",
      "21/09/16 18:51:00 WARN HiveConf: HiveConf of name hive.server2.operation.log.cleanup.delay does not exist\n",
      "21/09/16 18:51:00 WARN HiveConf: HiveConf of name hive.repl.dump.metadata.only does not exist\n",
      "21/09/16 18:51:00 WARN HiveConf: HiveConf of name hive.optimize.countdistinct does not exist\n",
      "21/09/16 18:51:00 WARN HiveConf: HiveConf of name hive.auto.convert.join.shuffle.max.size does not exist\n",
      "21/09/16 18:51:00 WARN HiveConf: HiveConf of name hive.llap.plugin.acl does not exist\n",
      "21/09/16 18:51:00 WARN HiveConf: HiveConf of name hive.metastore.schema.info.class does not exist\n",
      "21/09/16 18:51:00 WARN HiveConf: HiveConf of name hive.server2.tez.queue.access.check does not exist\n",
      "21/09/16 18:51:00 WARN HiveConf: HiveConf of name hive.llap.external.splits.temp.table.storage.format does not exist\n",
      "21/09/16 18:51:00 WARN HiveConf: HiveConf of name hive.llap.io.row.wrapper.enabled does not exist\n",
      "21/09/16 18:51:00 WARN HiveConf: HiveConf of name hive.constraint.notnull.enforce does not exist\n",
      "21/09/16 18:51:00 WARN HiveConf: HiveConf of name hive.cli.print.escape.crlf does not exist\n",
      "21/09/16 18:51:00 WARN HiveConf: HiveConf of name hive.trigger.validation.interval does not exist\n",
      "21/09/16 18:51:00 WARN HiveConf: HiveConf of name hive.server2.webui.cors.allowed.origins does not exist\n",
      "21/09/16 18:51:00 WARN HiveConf: HiveConf of name hive.server2.limit.connections.per.ipaddress does not exist\n",
      "21/09/16 18:51:00 WARN HiveConf: HiveConf of name hive.llap.external.splits.order.by.force.single.split does not exist\n",
      "21/09/16 18:51:00 WARN HiveConf: HiveConf of name hive.metastore.client.cache.stats.enabled does not exist\n",
      "21/09/16 18:51:00 WARN HiveConf: HiveConf of name hive.notification.event.poll.interval does not exist\n",
      "21/09/16 18:51:00 WARN HiveConf: HiveConf of name hive.transactional.concatenate.noblock does not exist\n",
      "21/09/16 18:51:00 WARN HiveConf: HiveConf of name hive.materializedview.rewriting.strategy does not exist\n",
      "21/09/16 18:51:00 WARN HiveConf: HiveConf of name hive.vectorized.if.expr.mode does not exist\n",
      "21/09/16 18:51:00 WARN HiveConf: HiveConf of name hive.exim.test.mode does not exist\n",
      "21/09/16 18:51:00 WARN HiveConf: HiveConf of name hive.query.results.cache.directory does not exist\n",
      "21/09/16 18:51:00 WARN HiveConf: HiveConf of name hive.query.results.cache.wait.for.pending.results does not exist\n",
      "21/09/16 18:51:00 WARN HiveConf: HiveConf of name hive.remove.orderby.in.subquery does not exist\n",
      "21/09/16 18:51:00 WARN HiveConf: HiveConf of name hive.tez.bmj.use.subcache does not exist\n",
      "21/09/16 18:51:00 WARN HiveConf: HiveConf of name hive.llap.io.vrb.queue.limit.min does not exist\n",
      "21/09/16 18:51:00 WARN HiveConf: HiveConf of name hive.server2.wm.pool.metrics does not exist\n",
      "21/09/16 18:51:00 WARN HiveConf: HiveConf of name hive.repl.add.raw.reserved.namespace does not exist\n",
      "21/09/16 18:51:00 WARN HiveConf: HiveConf of name hive.resource.use.hdfs.location does not exist\n",
      "21/09/16 18:51:00 WARN HiveConf: HiveConf of name hive.stats.num.nulls.estimate.percent does not exist\n",
      "21/09/16 18:51:00 WARN HiveConf: HiveConf of name hive.llap.io.acid does not exist\n",
      "21/09/16 18:51:00 WARN HiveConf: HiveConf of name hive.llap.zk.sm.session.timeout does not exist\n",
      "21/09/16 18:51:00 WARN HiveConf: HiveConf of name hive.vectorized.ptf.max.memory.buffering.batch.count does not exist\n",
      "21/09/16 18:51:00 WARN HiveConf: HiveConf of name hive.llap.task.scheduler.am.registry does not exist\n",
      "21/09/16 18:51:00 WARN HiveConf: HiveConf of name hive.druid.overlord.address.default does not exist\n",
      "21/09/16 18:51:00 WARN HiveConf: HiveConf of name hive.optimize.remove.sq_count_check does not exist\n",
      "21/09/16 18:51:00 WARN HiveConf: HiveConf of name hive.server2.webui.enable.cors does not exist\n",
      "21/09/16 18:51:00 WARN HiveConf: HiveConf of name hive.stats.retries.wait does not exist\n",
      "21/09/16 18:51:00 WARN HiveConf: HiveConf of name hive.vectorized.row.serde.inputformat.excludes does not exist\n",
      "21/09/16 18:51:00 WARN HiveConf: HiveConf of name hive.query.reexecution.stats.cache.size does not exist\n",
      "21/09/16 18:51:00 WARN HiveConf: HiveConf of name hive.combine.equivalent.work.optimization does not exist\n",
      "21/09/16 18:51:00 WARN HiveConf: HiveConf of name hive.lock.query.string.max.length does not exist\n",
      "21/09/16 18:51:00 WARN HiveConf: HiveConf of name hive.llap.io.track.cache.usage does not exist\n",
      "21/09/16 18:51:00 WARN HiveConf: HiveConf of name hive.use.orc.codec.pool does not exist\n",
      "21/09/16 18:51:00 WARN HiveConf: HiveConf of name hive.query.results.cache.max.size does not exist\n",
      "21/09/16 18:51:00 WARN HiveConf: HiveConf of name hive.repl.bootstrap.dump.open.txn.timeout does not exist\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "Method 2\n",
    "\n",
    "\n",
    "Loading spark dataframe by creating view and inserting it into hive\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "try:\n",
    "    # here test is a database name and just give anything for table name it will create automatically\n",
    "    spark.sql(\"create table test.test_data2 as select * from myview\")\n",
    "\n",
    "except Exception as e:\n",
    "    logger.error(e)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "21/09/16 18:51:16 WARN ResolveSessionCatalog: A Hive serde table will be created as there is no table provider specified. You can set spark.sql.legacy.createHiveTableByDefault to false so that native data source table will be created instead.\n",
      "21/09/16 18:51:17 WARN HiveMetaStore: Location: hdfs://localhost:9000/user/hive/warehouse/test.db/test_data2 specified for non-external table:test_data2\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Showing The hive tables"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "try:\n",
    "    \n",
    "    dfs = spark.sql(\"use test\")\n",
    "    dfs1 = spark.sql(\"show tables\")\n",
    "    dfs1.show()\n",
    "    \n",
    "\n",
    "except Exception as e:\n",
    "    logger.error(e)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+--------+----------+-----------+\n",
      "|database| tableName|isTemporary|\n",
      "+--------+----------+-----------+\n",
      "|    test| test_data|      false|\n",
      "|    test|test_data2|      false|\n",
      "|        |    myview|       true|\n",
      "+--------+----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit"
  },
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}